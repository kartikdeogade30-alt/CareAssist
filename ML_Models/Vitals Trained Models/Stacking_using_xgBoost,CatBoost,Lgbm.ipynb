{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Simple Stacking Ensemble Model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_predict\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import xgboost as xgb\n",
        "import catboost as cb\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('human_vital_signs_dataset_2024.csv')\n",
        "\n",
        "# Prepare data\n",
        "features = ['Heart Rate', 'Body Temperature', 'Oxygen Saturation',\n",
        "            'Systolic Blood Pressure', 'Diastolic Blood Pressure',\n",
        "            'Age', 'Gender', 'Weight (kg)', 'Height (m)', 'Derived_BMI']\n",
        "target = 'Risk Category'\n",
        "\n",
        "df['Gender'] = df['Gender'].map({'Male': 1, 'Female': 0})\n",
        "df['Risk'] = df[target].map({'Low Risk': 0, 'High Risk': 1})\n",
        "\n",
        "X = df[features]\n",
        "y = df['Risk']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"STACKING ENSEMBLE MODEL\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Test samples: {len(X_test)}\")\n",
        "\n",
        "# Step 1: Train base models\n",
        "print(\"\\nTraining base models...\")\n",
        "\n",
        "# XGBoost\n",
        "xgb_model = xgb.XGBClassifier(n_estimators=100, random_state=42,\n",
        "                              use_label_encoder=False, eval_metric='logloss')\n",
        "xgb_model.fit(X_train, y_train)\n",
        "xgb_preds = xgb_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# CatBoost\n",
        "cat_model = cb.CatBoostClassifier(iterations=100, random_seed=42, verbose=0)\n",
        "cat_model.fit(X_train, y_train, cat_features=['Gender'])\n",
        "cat_preds = cat_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# LightGBM\n",
        "lgb_model = lgb.LGBMClassifier(n_estimators=100, random_state=42)\n",
        "lgb_model.fit(X_train, y_train)\n",
        "lgb_preds = lgb_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Step 2: Create meta-features\n",
        "meta_X = np.column_stack([xgb_preds, cat_preds, lgb_preds])\n",
        "\n",
        "# Step 3: Train meta-model (Logistic Regression)\n",
        "meta_model = LogisticRegression(random_state=42)\n",
        "meta_model.fit(meta_X, y_test)\n",
        "\n",
        "# Step 4: Make final predictions\n",
        "final_preds = meta_model.predict(meta_X)\n",
        "\n",
        "# Evaluate\n",
        "print(\"\\nStacking Model Results:\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"Accuracy:  {accuracy_score(y_test, final_preds):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, final_preds):.4f}\")\n",
        "print(f\"Recall:    {recall_score(y_test, final_preds):.4f}\")\n",
        "print(f\"F1-Score:  {f1_score(y_test, final_preds):.4f}\")\n",
        "\n",
        "# Compare with individual models\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"INDIVIDUAL MODEL COMPARISON\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "models = {\n",
        "    'XGBoost': xgb_model,\n",
        "    'CatBoost': cat_model,\n",
        "    'LightGBM': lgb_model,\n",
        "    'Stacking': 'N/A'\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    if name != 'Stacking':\n",
        "        preds = model.predict(X_test)\n",
        "        acc = accuracy_score(y_test, preds)\n",
        "        print(f\"{name:10s}: Accuracy = {acc:.4f}\")\n",
        "\n",
        "print(f\"Stacking   : Accuracy = {accuracy_score(y_test, final_preds):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIwXVXbcysgq",
        "outputId": "5d4fc59d-fa01-49de-aaff-ec7796d2e66c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "STACKING ENSEMBLE MODEL\n",
            "==================================================\n",
            "Training samples: 160016\n",
            "Test samples: 40004\n",
            "\n",
            "Training base models...\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 84166, number of negative: 75850\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019143 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1443\n",
            "[LightGBM] [Info] Number of data points in the train set: 160016, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525985 -> initscore=0.104033\n",
            "[LightGBM] [Info] Start training from score 0.104033\n",
            "\n",
            "Stacking Model Results:\n",
            "----------------------------------------\n",
            "Accuracy:  0.9995\n",
            "Precision: 0.9995\n",
            "Recall:    0.9996\n",
            "F1-Score:  0.9995\n",
            "\n",
            "==================================================\n",
            "INDIVIDUAL MODEL COMPARISON\n",
            "==================================================\n",
            "XGBoost   : Accuracy = 0.9987\n",
            "CatBoost  : Accuracy = 0.9987\n",
            "LightGBM  : Accuracy = 0.9985\n",
            "Stacking   : Accuracy = 0.9995\n"
          ]
        }
      ]
    }
  ]
}