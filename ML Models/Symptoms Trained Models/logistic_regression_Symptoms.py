# -*- coding: utf-8 -*-
"""Logistic Regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iVxysLBTFSBpQnj2rAGXR6DTS7q0aZch
"""

import pandas as pd
import numpy as np

from sklearn.model_selection import (
    train_test_split, StratifiedKFold, GridSearchCV
)
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score,
    f1_score, classification_report, roc_auc_score
)

import warnings
warnings.filterwarnings("ignore")

# Load Dataset
df = pd.read_csv("dataset.csv")
print("Dataset Shape:", df.shape)

# Clean Symptoms
for col in df.columns:
    df[col] = df[col].astype(str).str.strip().replace('nan', '')

# Build Binary Symptom Matrix
all_symptoms = sorted(set(df.iloc[:, 1:].values.flatten()))
all_symptoms = [s for s in all_symptoms if s != '']

X = pd.DataFrame(0, index=df.index, columns=all_symptoms)

for i in range(len(df)):
    for symptom in df.iloc[i, 1:].values:
        if symptom:
            X.loc[i, symptom] = 1

# DROP RARE SYMPTOMS (VERY IMPORTANT)
min_occurrence = int(0.03 * len(X))  # appear in at least 3% of samples
X = X.loc[:, X.sum(axis=0) >= min_occurrence]

print("Remaining Symptoms after filtering:", X.shape[1])

# Encode Target
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(df['Disease'])

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.30,
    random_state=42,
    stratify=y
)

# MAX Anti-Overfitting Logistic Regression
base_model = LogisticRegression(
    solver='saga',
    penalty='elasticnet',
    class_weight='balanced',
    multi_class='multinomial',
    max_iter=5000,
    random_state=42
)

param_grid = {
    "C": [0.01, 0.05, 0.1],
    "l1_ratio": [0.3, 0.5, 0.7]
}

cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

grid = GridSearchCV(
    base_model,
    param_grid,
    scoring='f1_weighted',
    cv=cv,
    n_jobs=-1
)

grid.fit(X_train, y_train)

best_model = grid.best_estimator_

print("\nBest Hyperparameters:")
print(grid.best_params_)

# Evaluation
y_pred = best_model.predict(X_test)
y_proba = best_model.predict_proba(X_test)

print("\nFINAL MODEL PERFORMANCE")
print("=======================")
print(f"Accuracy  : {accuracy_score(y_test, y_pred):.4f}")
print(f"Precision : {precision_score(y_test, y_pred, average='weighted'):.4f}")
print(f"Recall    : {recall_score(y_test, y_pred, average='weighted'):.4f}")
print(f"F1-score  : {f1_score(y_test, y_pred, average='weighted'):.4f}")
print(f"ROC-AUC   : {roc_auc_score(y_test, y_proba, multi_class='ovr'):.4f}")

print("\nClassification Report:")
print(classification_report(
    y_test,
    y_pred,
    target_names=label_encoder.classes_
))